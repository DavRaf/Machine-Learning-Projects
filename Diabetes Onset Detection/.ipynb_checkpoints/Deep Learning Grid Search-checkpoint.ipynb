{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
       "       'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "# import the uci pima indians diabetes dataset\n",
    "filename = \"diabetes.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()\n",
    "df[df['Glucose'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  763.000000     733.000000     541.000000  394.000000   \n",
       "mean      3.845052  121.686763      72.405184      29.153420  155.548223   \n",
       "std       3.369578   30.535641      12.382158      10.476982  118.775855   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      64.000000      22.000000   76.250000   \n",
       "50%       3.000000  117.000000      72.000000      29.000000  125.000000   \n",
       "75%       6.000000  141.000000      80.000000      36.000000  190.000000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  757.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.457464                  0.471876   33.240885    0.348958  \n",
       "std      6.924988                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.300000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data, mark zero values as NaN and drop\n",
    "columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in columns:\n",
    "    df[col].replace(0, np.NaN, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301020</td>\n",
       "      <td>122.627551</td>\n",
       "      <td>70.663265</td>\n",
       "      <td>29.145408</td>\n",
       "      <td>156.056122</td>\n",
       "      <td>33.086224</td>\n",
       "      <td>0.523046</td>\n",
       "      <td>30.864796</td>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211424</td>\n",
       "      <td>30.860781</td>\n",
       "      <td>12.496092</td>\n",
       "      <td>10.516424</td>\n",
       "      <td>118.841690</td>\n",
       "      <td>7.027659</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>10.200777</td>\n",
       "      <td>0.471401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   392.000000  392.000000     392.000000     392.000000  392.000000   \n",
       "mean      3.301020  122.627551      70.663265      29.145408  156.056122   \n",
       "std       3.211424   30.860781      12.496092      10.516424  118.841690   \n",
       "min       0.000000   56.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      62.000000      21.000000   76.750000   \n",
       "50%       2.000000  119.000000      70.000000      29.000000  125.500000   \n",
       "75%       5.000000  143.000000      78.000000      37.000000  190.000000   \n",
       "max      17.000000  198.000000     110.000000      63.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  392.000000                392.000000  392.000000  392.000000  \n",
       "mean    33.086224                  0.523046   30.864796    0.331633  \n",
       "std      7.027659                  0.345488   10.200777    0.471401  \n",
       "min     18.200000                  0.085000   21.000000    0.000000  \n",
       "25%     28.400000                  0.269750   23.000000    0.000000  \n",
       "50%     33.200000                  0.449500   27.000000    0.000000  \n",
       "75%     37.100000                  0.687000   36.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Summarize the number of rows and columns in df\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input (X) and output (y)\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 8)\n",
      "(392,)\n",
      "[0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using sklearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.021726e-17</td>\n",
       "      <td>3.129583e-17</td>\n",
       "      <td>-4.641624e-16</td>\n",
       "      <td>1.042250e-16</td>\n",
       "      <td>6.485742e-17</td>\n",
       "      <td>1.543550e-16</td>\n",
       "      <td>3.880116e-17</td>\n",
       "      <td>1.028089e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.029213e+00</td>\n",
       "      <td>-2.161731e+00</td>\n",
       "      <td>-3.739001e+00</td>\n",
       "      <td>-2.108484e+00</td>\n",
       "      <td>-1.196867e+00</td>\n",
       "      <td>-2.120941e+00</td>\n",
       "      <td>-1.269525e+00</td>\n",
       "      <td>-9.682991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.174265e-01</td>\n",
       "      <td>-7.665958e-01</td>\n",
       "      <td>-6.941640e-01</td>\n",
       "      <td>-7.755315e-01</td>\n",
       "      <td>-6.681786e-01</td>\n",
       "      <td>-6.676780e-01</td>\n",
       "      <td>-7.340909e-01</td>\n",
       "      <td>-7.719850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.056403e-01</td>\n",
       "      <td>-1.176959e-01</td>\n",
       "      <td>-5.314565e-02</td>\n",
       "      <td>-1.384444e-02</td>\n",
       "      <td>-2.574448e-01</td>\n",
       "      <td>1.621036e-02</td>\n",
       "      <td>-2.131475e-01</td>\n",
       "      <td>-3.793569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.297185e-01</td>\n",
       "      <td>6.609841e-01</td>\n",
       "      <td>5.878727e-01</td>\n",
       "      <td>7.478426e-01</td>\n",
       "      <td>2.859877e-01</td>\n",
       "      <td>5.718696e-01</td>\n",
       "      <td>4.751644e-01</td>\n",
       "      <td>5.040564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.271153e+00</td>\n",
       "      <td>2.445459e+00</td>\n",
       "      <td>3.151946e+00</td>\n",
       "      <td>3.223325e+00</td>\n",
       "      <td>5.812990e+00</td>\n",
       "      <td>4.846172e+00</td>\n",
       "      <td>5.497667e+00</td>\n",
       "      <td>4.921123e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02   \n",
       "mean  -4.021726e-17  3.129583e-17 -4.641624e-16  1.042250e-16  6.485742e-17   \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00   \n",
       "min   -1.029213e+00 -2.161731e+00 -3.739001e+00 -2.108484e+00 -1.196867e+00   \n",
       "25%   -7.174265e-01 -7.665958e-01 -6.941640e-01 -7.755315e-01 -6.681786e-01   \n",
       "50%   -4.056403e-01 -1.176959e-01 -5.314565e-02 -1.384444e-02 -2.574448e-01   \n",
       "75%    5.297185e-01  6.609841e-01  5.878727e-01  7.478426e-01  2.859877e-01   \n",
       "max    4.271153e+00  2.445459e+00  3.151946e+00  3.223325e+00  5.812990e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  \n",
       "mean   1.543550e-16  3.880116e-17  1.028089e-16  \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  \n",
       "min   -2.120941e+00 -1.269525e+00 -9.682991e-01  \n",
       "25%   -6.676780e-01 -7.340909e-01 -7.719850e-01  \n",
       "50%    1.621036e-02 -2.131475e-01 -3.793569e-01  \n",
       "75%    5.718696e-01  4.751644e-01  5.040564e-01  \n",
       "max    4.846172e+00  5.497667e+00  4.921123e+00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform and display the training data\n",
    "X_standardized = scaler.transform(X)\n",
    "\n",
    "data = pd.DataFrame(X_standardized)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Start defining the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.6333 - acc: 0.6897\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.4840 - acc: 0.6973\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 204us/step - loss: 0.4422 - acc: 0.6973\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 307us/step - loss: 0.4246 - acc: 0.6973\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 323us/step - loss: 0.4142 - acc: 0.8123\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 190us/step - loss: 0.4022 - acc: 0.8276\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 325us/step - loss: 0.3971 - acc: 0.8352\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3850 - acc: 0.8276\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 304us/step - loss: 0.3844 - acc: 0.8199\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 257us/step - loss: 0.3756 - acc: 0.8238\n",
      "131/131 [==============================] - 0s 15us/step\n",
      "261/261 [==============================] - 0s 27us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.7251908378746673, total=   2.4s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.6607 - acc: 0.7280\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.6058 - acc: 0.7816\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 221us/step - loss: 0.5757 - acc: 0.7854\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.5311 - acc: 0.8123\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.5161 - acc: 0.8008\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.5176 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.5040 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 259us/step - loss: 0.4814 - acc: 0.7931\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.4738 - acc: 0.8008\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 162us/step - loss: 0.4682 - acc: 0.8084\n",
      "131/131 [==============================] - 0s 50us/step\n",
      "261/261 [==============================] - 0s 17us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.7709923664122137, total=   1.6s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.6352 - acc: 0.6450\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.5274 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.5014 - acc: 0.6908\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 226us/step - loss: 0.4988 - acc: 0.7595\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 216us/step - loss: 0.4885 - acc: 0.7786\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4830 - acc: 0.7824\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 170us/step - loss: 0.4775 - acc: 0.7824\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 270us/step - loss: 0.4745 - acc: 0.7786\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 199us/step - loss: 0.4702 - acc: 0.7939\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.4753 - acc: 0.7748\n",
      "130/130 [==============================] - 0s 15us/step\n",
      "262/262 [==============================] - 0s 33us/step\n",
      "[CV]  batch_size=10, epochs=10, score=0.8230769175749558, total=   1.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.6128 - acc: 0.6935\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.4619 - acc: 0.6973\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 171us/step - loss: 0.4308 - acc: 0.6973\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.4154 - acc: 0.7816\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.4076 - acc: 0.8391\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 259us/step - loss: 0.3957 - acc: 0.8352\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.3864 - acc: 0.8276\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 154us/step - loss: 0.3786 - acc: 0.8544\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3804 - acc: 0.8391\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 158us/step - loss: 0.3717 - acc: 0.8429\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3769 - acc: 0.8314\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.3585 - acc: 0.8582\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3528 - acc: 0.8544\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 196us/step - loss: 0.3446 - acc: 0.8506\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3385 - acc: 0.8659\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.3385 - acc: 0.8621\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.3272 - acc: 0.8659\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3272 - acc: 0.8659\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3167 - acc: 0.8697\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 166us/step - loss: 0.3112 - acc: 0.8774\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3073 - acc: 0.8621\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 158us/step - loss: 0.3117 - acc: 0.8774\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 219us/step - loss: 0.3031 - acc: 0.8774\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.3021 - acc: 0.8736\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.2993 - acc: 0.8736\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.3109 - acc: 0.8774\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.3010 - acc: 0.8774\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 135us/step - loss: 0.3001 - acc: 0.8697\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.2862 - acc: 0.8812\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 177us/step - loss: 0.2840 - acc: 0.9004\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2826 - acc: 0.8851\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 183us/step - loss: 0.2773 - acc: 0.8812\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.2766 - acc: 0.8927\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2781 - acc: 0.8774\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2866 - acc: 0.8889\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2967 - acc: 0.8812\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.2818 - acc: 0.8812\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.2751 - acc: 0.8812\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2697 - acc: 0.8927\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2721 - acc: 0.8889\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2610 - acc: 0.8966\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 209us/step - loss: 0.2706 - acc: 0.9080\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.2666 - acc: 0.8889\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.2580 - acc: 0.9042\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2583 - acc: 0.8966\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.2562 - acc: 0.8927\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2564 - acc: 0.9004\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 171us/step - loss: 0.2562 - acc: 0.9080\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 154us/step - loss: 0.2470 - acc: 0.9042\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2706 - acc: 0.9080\n",
      "131/131 [==============================] - 0s 38us/step\n",
      "261/261 [==============================] - 0s 40us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.7328244229309432, total=   3.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.6354 - acc: 0.6398\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 204us/step - loss: 0.5013 - acc: 0.7816\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.4615 - acc: 0.7893\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 50us/step - loss: 0.4444 - acc: 0.7854\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.4273 - acc: 0.8161\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 196us/step - loss: 0.4254 - acc: 0.8084\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.4130 - acc: 0.8008\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.4086 - acc: 0.8084\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.4005 - acc: 0.8161\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 248us/step - loss: 0.3937 - acc: 0.8276\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.3920 - acc: 0.8238\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3767 - acc: 0.8391\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.3836 - acc: 0.8199\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.3842 - acc: 0.8276\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.3736 - acc: 0.8391\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.3713 - acc: 0.8467\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3783 - acc: 0.8429\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3571 - acc: 0.8429\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3619 - acc: 0.8506\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.3591 - acc: 0.8429\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3647 - acc: 0.8352\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 156us/step - loss: 0.3450 - acc: 0.8429\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3630 - acc: 0.8506\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3623 - acc: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3397 - acc: 0.8582\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3318 - acc: 0.8659\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3260 - acc: 0.8697\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3300 - acc: 0.8697\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3298 - acc: 0.8659\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3353 - acc: 0.8659\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 210us/step - loss: 0.3254 - acc: 0.8621\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3197 - acc: 0.8736\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3280 - acc: 0.8621\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3175 - acc: 0.8812\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3134 - acc: 0.8851\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3122 - acc: 0.8697\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.3173 - acc: 0.8774\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.3079 - acc: 0.8659\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3014 - acc: 0.8697\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3146 - acc: 0.8582\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.3116 - acc: 0.8621\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2945 - acc: 0.8851\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.2927 - acc: 0.8812\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 190us/step - loss: 0.2915 - acc: 0.8774\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 144us/step - loss: 0.3128 - acc: 0.8697\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.3050 - acc: 0.8659\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2829 - acc: 0.8812\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.2806 - acc: 0.8774\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 210us/step - loss: 0.2885 - acc: 0.8812\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2848 - acc: 0.8697\n",
      "131/131 [==============================] - 0s 15us/step\n",
      "261/261 [==============================] - 0s 27us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.7786259514684896, total=   3.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.6279 - acc: 0.6450\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4939 - acc: 0.7443\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.4829 - acc: 0.7366\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 120us/step - loss: 0.4679 - acc: 0.7595\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 212us/step - loss: 0.4622 - acc: 0.7519\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 270us/step - loss: 0.4588 - acc: 0.7634\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4502 - acc: 0.7824\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 205us/step - loss: 0.4436 - acc: 0.7824\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 197us/step - loss: 0.4458 - acc: 0.7710\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.4416 - acc: 0.7786\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.4358 - acc: 0.7863\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 230us/step - loss: 0.4289 - acc: 0.7863\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.4368 - acc: 0.7634\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 147us/step - loss: 0.4241 - acc: 0.7939\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 249us/step - loss: 0.4265 - acc: 0.7824\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 192us/step - loss: 0.4191 - acc: 0.8015\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 203us/step - loss: 0.4189 - acc: 0.8015\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.4087 - acc: 0.8053\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4058 - acc: 0.8092\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.4105 - acc: 0.8168\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.4056 - acc: 0.8092\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.3966 - acc: 0.8168\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 283us/step - loss: 0.3986 - acc: 0.8244\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4014 - acc: 0.8244\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 182us/step - loss: 0.4086 - acc: 0.8015\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.4058 - acc: 0.8092\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.4021 - acc: 0.8206\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 165us/step - loss: 0.3933 - acc: 0.8282\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 300us/step - loss: 0.3917 - acc: 0.8321\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.3840 - acc: 0.8359\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.3804 - acc: 0.8282\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.3819 - acc: 0.8511\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 102us/step - loss: 0.3770 - acc: 0.8359\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3776 - acc: 0.8206\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 102us/step - loss: 0.3855 - acc: 0.8397\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.3776 - acc: 0.8435\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3703 - acc: 0.8588\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 167us/step - loss: 0.3744 - acc: 0.8435\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3804 - acc: 0.8588\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 228us/step - loss: 0.3642 - acc: 0.8550\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.3609 - acc: 0.8664\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.3618 - acc: 0.8550\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.3619 - acc: 0.8702\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3592 - acc: 0.8321\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 214us/step - loss: 0.3623 - acc: 0.8550\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.3550 - acc: 0.8511\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 343us/step - loss: 0.3429 - acc: 0.8664\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 228us/step - loss: 0.3503 - acc: 0.8779\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 304us/step - loss: 0.3537 - acc: 0.8511\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.3387 - acc: 0.8740\n",
      "130/130 [==============================] - 0s 81us/step\n",
      "262/262 [==============================] - 0s 109us/step\n",
      "[CV]  batch_size=10, epochs=50, score=0.8461538415688735, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 50us/step - loss: 0.6010 - acc: 0.6858\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 156us/step - loss: 0.4651 - acc: 0.6973\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 204us/step - loss: 0.4274 - acc: 0.7088\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.4152 - acc: 0.8161\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 311us/step - loss: 0.4055 - acc: 0.8314\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3957 - acc: 0.8238\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3865 - acc: 0.8314\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3772 - acc: 0.8276\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 227us/step - loss: 0.3706 - acc: 0.8391\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.3642 - acc: 0.8314\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3579 - acc: 0.8467\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3604 - acc: 0.8352\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.3476 - acc: 0.8314\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3623 - acc: 0.8352\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 321us/step - loss: 0.3525 - acc: 0.8276\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.3410 - acc: 0.8352\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 307us/step - loss: 0.3297 - acc: 0.8467\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3251 - acc: 0.8582\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 367us/step - loss: 0.3280 - acc: 0.8544\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3165 - acc: 0.8659\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.3140 - acc: 0.8621\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3133 - acc: 0.8659\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 282us/step - loss: 0.3391 - acc: 0.8544\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 265us/step - loss: 0.3109 - acc: 0.8774\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 198us/step - loss: 0.3068 - acc: 0.8774\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.3000 - acc: 0.8774\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 328us/step - loss: 0.2959 - acc: 0.8774\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 116us/step - loss: 0.2945 - acc: 0.8927\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.2945 - acc: 0.8889\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2898 - acc: 0.8774\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.2914 - acc: 0.8927\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.2884 - acc: 0.8927\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 0s 307us/step - loss: 0.3009 - acc: 0.8736\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2819 - acc: 0.9004\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.2896 - acc: 0.8812\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.2805 - acc: 0.8966\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.2812 - acc: 0.8927\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.2768 - acc: 0.8889\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2743 - acc: 0.9042\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 248us/step - loss: 0.2743 - acc: 0.8966\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2754 - acc: 0.8966\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.2845 - acc: 0.9042\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 283us/step - loss: 0.2793 - acc: 0.8966\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 202us/step - loss: 0.2794 - acc: 0.8966\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2747 - acc: 0.8927\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2780 - acc: 0.8851\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2713 - acc: 0.9004\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.2733 - acc: 0.8966\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2706 - acc: 0.9004\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2649 - acc: 0.9004\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 278us/step - loss: 0.2640 - acc: 0.9080\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 232us/step - loss: 0.2633 - acc: 0.9004\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.2671 - acc: 0.9042\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 177us/step - loss: 0.2649 - acc: 0.9080\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 221us/step - loss: 0.2630 - acc: 0.9080\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.2638 - acc: 0.9004\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 217us/step - loss: 0.3330 - acc: 0.8659\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.2928 - acc: 0.8736\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.2666 - acc: 0.8812\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.2674 - acc: 0.8889\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2629 - acc: 0.8966\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 156us/step - loss: 0.2673 - acc: 0.8927\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.2641 - acc: 0.9004\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 234us/step - loss: 0.2720 - acc: 0.8889\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.2629 - acc: 0.9004\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2606 - acc: 0.8966\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.2588 - acc: 0.9042\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.2555 - acc: 0.9157\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.2577 - acc: 0.9004\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.2560 - acc: 0.9004\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 334us/step - loss: 0.2620 - acc: 0.9004\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 284us/step - loss: 0.2704 - acc: 0.8966\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 300us/step - loss: 0.2536 - acc: 0.8966\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 313us/step - loss: 0.2534 - acc: 0.8927\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 200us/step - loss: 0.2534 - acc: 0.9042\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 202us/step - loss: 0.2472 - acc: 0.9119\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.2502 - acc: 0.9042\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.2450 - acc: 0.9080\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 286us/step - loss: 0.2493 - acc: 0.9080\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 242us/step - loss: 0.2426 - acc: 0.9234\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.2515 - acc: 0.9004\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2565 - acc: 0.8966\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 125us/step - loss: 0.2462 - acc: 0.9080\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.2414 - acc: 0.9119\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 144us/step - loss: 0.2648 - acc: 0.8966\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 221us/step - loss: 0.2448 - acc: 0.9119\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.2368 - acc: 0.9119\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2541 - acc: 0.8927\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.2469 - acc: 0.9004\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.2477 - acc: 0.9119\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.2408 - acc: 0.9119\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 162us/step - loss: 0.2326 - acc: 0.9195\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2319 - acc: 0.9119\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.2283 - acc: 0.9157\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.2268 - acc: 0.9195\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2278 - acc: 0.9234\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.2335 - acc: 0.9119\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.2271 - acc: 0.9157\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.2394 - acc: 0.9004\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.2342 - acc: 0.9119\n",
      "131/131 [==============================] - 0s 27us/step\n",
      "261/261 [==============================] - 0s 19us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.7175572482684186, total=   7.2s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   24.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.6231 - acc: 0.7203\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.4737 - acc: 0.7739\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.4470 - acc: 0.7969\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4370 - acc: 0.7931\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.4249 - acc: 0.8084\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.4258 - acc: 0.8046\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.4123 - acc: 0.8123\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.4194 - acc: 0.8161\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3987 - acc: 0.8238\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.4002 - acc: 0.8276\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3917 - acc: 0.8314\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 132us/step - loss: 0.3881 - acc: 0.8238\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 154us/step - loss: 0.3960 - acc: 0.8238\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3864 - acc: 0.8314\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3889 - acc: 0.8352\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.3837 - acc: 0.8352\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.3790 - acc: 0.8352\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3883 - acc: 0.8314\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.3791 - acc: 0.8391\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3735 - acc: 0.8352\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3704 - acc: 0.8467\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3629 - acc: 0.8506\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.4032 - acc: 0.8199\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 177us/step - loss: 0.3700 - acc: 0.8391\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3598 - acc: 0.8467\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3531 - acc: 0.8429\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3513 - acc: 0.8467\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3490 - acc: 0.8506\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.3457 - acc: 0.8506\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3398 - acc: 0.8467\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3417 - acc: 0.8582\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.3315 - acc: 0.8429\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.3285 - acc: 0.8544\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3310 - acc: 0.8391\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3259 - acc: 0.8506\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3231 - acc: 0.8544\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3161 - acc: 0.8506\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3153 - acc: 0.8582\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3075 - acc: 0.8697\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3231 - acc: 0.8467\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3096 - acc: 0.8659\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3143 - acc: 0.8506\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3079 - acc: 0.8544\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3068 - acc: 0.8659\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.3104 - acc: 0.8582\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3265 - acc: 0.8659\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3405 - acc: 0.8506\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3098 - acc: 0.8621\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 135us/step - loss: 0.2932 - acc: 0.8621\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2820 - acc: 0.8774\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2751 - acc: 0.8697\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.2782 - acc: 0.8812\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2736 - acc: 0.8697\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2781 - acc: 0.8621\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.2739 - acc: 0.8774\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.2715 - acc: 0.8697\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.2722 - acc: 0.8697\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.2714 - acc: 0.8697\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.2630 - acc: 0.8774\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2629 - acc: 0.8812\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2655 - acc: 0.8467\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.2480 - acc: 0.8812\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3182 - acc: 0.8391\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.2748 - acc: 0.8736\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2613 - acc: 0.8544\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2512 - acc: 0.8736\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 144us/step - loss: 0.2457 - acc: 0.8736\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2470 - acc: 0.8736\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.2409 - acc: 0.8774\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2443 - acc: 0.8736\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.2408 - acc: 0.8697\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.2370 - acc: 0.8774\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2332 - acc: 0.8736\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.2361 - acc: 0.8774\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.2327 - acc: 0.8774\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 139us/step - loss: 0.2251 - acc: 0.8812\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2270 - acc: 0.8889\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 156us/step - loss: 0.2571 - acc: 0.8582\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.2541 - acc: 0.8621\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.2467 - acc: 0.8621\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2407 - acc: 0.8659\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.2291 - acc: 0.8774\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.2256 - acc: 0.8774\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 117us/step - loss: 0.2286 - acc: 0.8774\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.2302 - acc: 0.8697\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 186us/step - loss: 0.2276 - acc: 0.8659\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.2695 - acc: 0.8966\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2487 - acc: 0.8697\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.2273 - acc: 0.8812\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2501 - acc: 0.8697\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2663 - acc: 0.8659\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.2234 - acc: 0.8736\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 167us/step - loss: 0.2268 - acc: 0.8812\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 246us/step - loss: 0.2104 - acc: 0.8812\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2155 - acc: 0.8697\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 190us/step - loss: 0.2261 - acc: 0.8774\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.2132 - acc: 0.8851\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.2072 - acc: 0.8889\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.2301 - acc: 0.8889\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 190us/step - loss: 0.2035 - acc: 0.8889\n",
      "131/131 [==============================] - 0s 15us/step\n",
      "261/261 [==============================] - 0s 35us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.7251908424246403, total=   4.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.5967 - acc: 0.6412\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.5242 - acc: 0.6527\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 0s 169us/step - loss: 0.5022 - acc: 0.7061\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.4929 - acc: 0.7557\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4890 - acc: 0.7672\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4826 - acc: 0.7710\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 0s 176us/step - loss: 0.4766 - acc: 0.7748\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - 0s 260us/step - loss: 0.4731 - acc: 0.7634\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.4647 - acc: 0.7939\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4608 - acc: 0.7824\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 0s 55us/step - loss: 0.4553 - acc: 0.7939\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.4518 - acc: 0.7786\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 0s 61us/step - loss: 0.4466 - acc: 0.7786\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - 0s 176us/step - loss: 0.4436 - acc: 0.8015\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - 0s 247us/step - loss: 0.4467 - acc: 0.7977\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - 0s 268us/step - loss: 0.4326 - acc: 0.8092\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - 0s 216us/step - loss: 0.4347 - acc: 0.8053\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4272 - acc: 0.8168\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - 0s 258us/step - loss: 0.4248 - acc: 0.8053\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - 0s 165us/step - loss: 0.4263 - acc: 0.8015\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - 0s 165us/step - loss: 0.4233 - acc: 0.8168\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4192 - acc: 0.8092\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.4244 - acc: 0.7977\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - 0s 153us/step - loss: 0.4195 - acc: 0.8130\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.4160 - acc: 0.8206\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - 0s 186us/step - loss: 0.4154 - acc: 0.8206\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - 0s 151us/step - loss: 0.4140 - acc: 0.7939\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - 0s 170us/step - loss: 0.4055 - acc: 0.8130\n",
      "Epoch 29/100\n",
      "262/262 [==============================] - 0s 161us/step - loss: 0.4054 - acc: 0.7977\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - 0s 142us/step - loss: 0.4141 - acc: 0.7977\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - 0s 180us/step - loss: 0.4108 - acc: 0.8053\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.4020 - acc: 0.8244\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.4029 - acc: 0.8092\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - 0s 147us/step - loss: 0.3979 - acc: 0.8130\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3956 - acc: 0.8168\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3928 - acc: 0.8206\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.3902 - acc: 0.8092\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3947 - acc: 0.8359\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.3953 - acc: 0.8282\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.3818 - acc: 0.8282\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3877 - acc: 0.8092\n",
      "Epoch 42/100\n",
      "262/262 [==============================] - 0s 163us/step - loss: 0.3828 - acc: 0.8397\n",
      "Epoch 43/100\n",
      "262/262 [==============================] - 0s 151us/step - loss: 0.3876 - acc: 0.8321\n",
      "Epoch 44/100\n",
      "262/262 [==============================] - 0s 180us/step - loss: 0.3757 - acc: 0.8435\n",
      "Epoch 45/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3787 - acc: 0.8359\n",
      "Epoch 46/100\n",
      "262/262 [==============================] - 0s 158us/step - loss: 0.3728 - acc: 0.8282\n",
      "Epoch 47/100\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3725 - acc: 0.8321\n",
      "Epoch 48/100\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3692 - acc: 0.8282\n",
      "Epoch 49/100\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.3752 - acc: 0.8321\n",
      "Epoch 50/100\n",
      "262/262 [==============================] - 0s 166us/step - loss: 0.3650 - acc: 0.8511\n",
      "Epoch 51/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.3642 - acc: 0.8435\n",
      "Epoch 52/100\n",
      "262/262 [==============================] - 0s 159us/step - loss: 0.3640 - acc: 0.8359\n",
      "Epoch 53/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.3649 - acc: 0.8397\n",
      "Epoch 54/100\n",
      "262/262 [==============================] - 0s 195us/step - loss: 0.3708 - acc: 0.8397\n",
      "Epoch 55/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.3627 - acc: 0.8435\n",
      "Epoch 56/100\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.3558 - acc: 0.8397\n",
      "Epoch 57/100\n",
      "262/262 [==============================] - 0s 172us/step - loss: 0.3583 - acc: 0.8435\n",
      "Epoch 58/100\n",
      "262/262 [==============================] - 0s 193us/step - loss: 0.3518 - acc: 0.8435\n",
      "Epoch 59/100\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.3500 - acc: 0.8473\n",
      "Epoch 60/100\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.3548 - acc: 0.8397\n",
      "Epoch 61/100\n",
      "262/262 [==============================] - 0s 151us/step - loss: 0.3504 - acc: 0.8397\n",
      "Epoch 62/100\n",
      "262/262 [==============================] - 0s 147us/step - loss: 0.3590 - acc: 0.8359\n",
      "Epoch 63/100\n",
      "262/262 [==============================] - 0s 151us/step - loss: 0.3467 - acc: 0.8435\n",
      "Epoch 64/100\n",
      "262/262 [==============================] - 0s 166us/step - loss: 0.3467 - acc: 0.8550\n",
      "Epoch 65/100\n",
      "262/262 [==============================] - 0s 161us/step - loss: 0.3440 - acc: 0.8473\n",
      "Epoch 66/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3333 - acc: 0.8511\n",
      "Epoch 67/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3383 - acc: 0.8511\n",
      "Epoch 68/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.5252 - acc: 0.600 - 0s 163us/step - loss: 0.3334 - acc: 0.8511\n",
      "Epoch 69/100\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.3344 - acc: 0.8588\n",
      "Epoch 70/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3363 - acc: 0.8435\n",
      "Epoch 71/100\n",
      "262/262 [==============================] - 0s 142us/step - loss: 0.3477 - acc: 0.8550\n",
      "Epoch 72/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.3407 - acc: 0.8588\n",
      "Epoch 73/100\n",
      "262/262 [==============================] - 0s 212us/step - loss: 0.3220 - acc: 0.8550\n",
      "Epoch 74/100\n",
      "262/262 [==============================] - 0s 224us/step - loss: 0.3234 - acc: 0.8664\n",
      "Epoch 75/100\n",
      "262/262 [==============================] - 0s 176us/step - loss: 0.3292 - acc: 0.8588\n",
      "Epoch 76/100\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.3245 - acc: 0.8588\n",
      "Epoch 77/100\n",
      "262/262 [==============================] - 0s 170us/step - loss: 0.3245 - acc: 0.8588\n",
      "Epoch 78/100\n",
      "262/262 [==============================] - 0s 145us/step - loss: 0.3273 - acc: 0.8550\n",
      "Epoch 79/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.3345 - acc: 0.8473\n",
      "Epoch 80/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.3148 - acc: 0.8511\n",
      "Epoch 81/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3170 - acc: 0.8740\n",
      "Epoch 82/100\n",
      "262/262 [==============================] - 0s 295us/step - loss: 0.3146 - acc: 0.8664\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 348us/step - loss: 0.3086 - acc: 0.8664\n",
      "Epoch 84/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3079 - acc: 0.8626\n",
      "Epoch 85/100\n",
      "262/262 [==============================] - 0s 320us/step - loss: 0.3135 - acc: 0.8626\n",
      "Epoch 86/100\n",
      "262/262 [==============================] - 0s 214us/step - loss: 0.3111 - acc: 0.8626\n",
      "Epoch 87/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3093 - acc: 0.8702\n",
      "Epoch 88/100\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.3083 - acc: 0.8550\n",
      "Epoch 89/100\n",
      "262/262 [==============================] - 0s 170us/step - loss: 0.3129 - acc: 0.8550\n",
      "Epoch 90/100\n",
      "262/262 [==============================] - 0s 191us/step - loss: 0.3041 - acc: 0.8626\n",
      "Epoch 91/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.2959 - acc: 0.8588\n",
      "Epoch 92/100\n",
      "262/262 [==============================] - 0s 144us/step - loss: 0.3262 - acc: 0.8779\n",
      "Epoch 93/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.3046 - acc: 0.8664\n",
      "Epoch 94/100\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.3050 - acc: 0.8626\n",
      "Epoch 95/100\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.2989 - acc: 0.8511\n",
      "Epoch 96/100\n",
      "262/262 [==============================] - 0s 281us/step - loss: 0.2903 - acc: 0.8664\n",
      "Epoch 97/100\n",
      "262/262 [==============================] - 0s 377us/step - loss: 0.3013 - acc: 0.8626\n",
      "Epoch 98/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.2962 - acc: 0.8779\n",
      "Epoch 99/100\n",
      "262/262 [==============================] - 0s 289us/step - loss: 0.2979 - acc: 0.8626\n",
      "Epoch 100/100\n",
      "262/262 [==============================] - 0s 228us/step - loss: 0.3276 - acc: 0.8511\n",
      "130/130 [==============================] - 0s 23us/step\n",
      "262/262 [==============================] - 0s 33us/step\n",
      "[CV]  batch_size=10, epochs=100, score=0.8230769175749558, total=   5.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.6706 - acc: 0.6552\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.5194 - acc: 0.6973\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.4662 - acc: 0.6973\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.4340 - acc: 0.6973\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 48us/step - loss: 0.4213 - acc: 0.6973\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4118 - acc: 0.7395\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4080 - acc: 0.8123\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4009 - acc: 0.8123\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3989 - acc: 0.8123\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3912 - acc: 0.8276\n",
      "131/131 [==============================] - 0s 8us/step\n",
      "261/261 [==============================] - 0s 12us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.7557251903846973, total=   1.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.6750 - acc: 0.7356\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.6164 - acc: 0.7663\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.5298 - acc: 0.7854\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.4575 - acc: 0.7816\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.4470 - acc: 0.7931\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.4308 - acc: 0.8008\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.4474 - acc: 0.7969\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.4382 - acc: 0.8008\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.4276 - acc: 0.7931\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.4212 - acc: 0.8008\n",
      "131/131 [==============================] - 0s 7us/step\n",
      "261/261 [==============================] - 0s 13us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.7633587900008864, total=   1.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "262/262 [==============================] - 0s 32us/step - loss: 0.6790 - acc: 0.6412\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.6127 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.5123 - acc: 0.7214\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.4786 - acc: 0.7634\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.4726 - acc: 0.7481\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4642 - acc: 0.7634\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 58us/step - loss: 0.4642 - acc: 0.7519\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 157us/step - loss: 0.4450 - acc: 0.7977\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 102us/step - loss: 0.4421 - acc: 0.7824\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.4402 - acc: 0.7863\n",
      "130/130 [==============================] - 0s 35us/step\n",
      "262/262 [==============================] - 0s 13us/step\n",
      "[CV]  batch_size=20, epochs=10, score=0.8384615457974948, total=   1.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.6640 - acc: 0.6935\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.5841 - acc: 0.6973\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.5015 - acc: 0.6973\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.4581 - acc: 0.6973\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.4377 - acc: 0.6973\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4262 - acc: 0.6973\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.4153 - acc: 0.6973\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.4093 - acc: 0.8123\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.4084 - acc: 0.8238\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.4038 - acc: 0.8276\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.3965 - acc: 0.8238\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3931 - acc: 0.8238\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3918 - acc: 0.8276\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3877 - acc: 0.8391\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3851 - acc: 0.8238\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3857 - acc: 0.8238\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3828 - acc: 0.8352\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3731 - acc: 0.8314\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3682 - acc: 0.8314\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3624 - acc: 0.8276\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3600 - acc: 0.8352\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3559 - acc: 0.8429\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3527 - acc: 0.8429\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3494 - acc: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3465 - acc: 0.8506\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3391 - acc: 0.8544\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3355 - acc: 0.8582\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3326 - acc: 0.8544\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3343 - acc: 0.8506\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3363 - acc: 0.8506\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3283 - acc: 0.8582\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3300 - acc: 0.8659\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3271 - acc: 0.8621\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.3249 - acc: 0.8621\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3206 - acc: 0.8697\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3174 - acc: 0.8659\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.3153 - acc: 0.8697\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3134 - acc: 0.8697\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3368 - acc: 0.8582\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3330 - acc: 0.8544\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3129 - acc: 0.8697\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3055 - acc: 0.8736\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3077 - acc: 0.8812\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3190 - acc: 0.8736\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3310 - acc: 0.8621\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3193 - acc: 0.8697\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 77us/step - loss: 0.3122 - acc: 0.8774\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3258 - acc: 0.8697\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3170 - acc: 0.8697\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3001 - acc: 0.8736\n",
      "131/131 [==============================] - 0s 11us/step\n",
      "261/261 [==============================] - 0s 19us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.7022900754258833, total=   2.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.6597 - acc: 0.6475\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 66us/step - loss: 0.5476 - acc: 0.6935\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4878 - acc: 0.7816\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 27us/step - loss: 0.4606 - acc: 0.7816\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.4443 - acc: 0.7854\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.4357 - acc: 0.7854\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.4258 - acc: 0.8046\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4182 - acc: 0.8008\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.4145 - acc: 0.7969\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 135us/step - loss: 0.4064 - acc: 0.8084\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.4122 - acc: 0.8161\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4038 - acc: 0.8199\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.4075 - acc: 0.8123\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3979 - acc: 0.8238\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3924 - acc: 0.8161\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3915 - acc: 0.8123\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.4020 - acc: 0.8084\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3911 - acc: 0.8314\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.3890 - acc: 0.8391\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3972 - acc: 0.8276\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 40us/step - loss: 0.3882 - acc: 0.8352\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3814 - acc: 0.8276\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.3873 - acc: 0.8161\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3817 - acc: 0.8276\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 36us/step - loss: 0.3746 - acc: 0.8391\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 141us/step - loss: 0.3699 - acc: 0.8352\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3708 - acc: 0.8352\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3718 - acc: 0.8314\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3688 - acc: 0.8352\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3688 - acc: 0.8352\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.3617 - acc: 0.8352\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3581 - acc: 0.8467\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 187us/step - loss: 0.3578 - acc: 0.8467\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3512 - acc: 0.8467\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3545 - acc: 0.8506\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3468 - acc: 0.8506\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3439 - acc: 0.8582\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3433 - acc: 0.8467\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3371 - acc: 0.8697\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3327 - acc: 0.8659\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3346 - acc: 0.8582\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3374 - acc: 0.8467\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 112us/step - loss: 0.3818 - acc: 0.8467\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.3620 - acc: 0.8352\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.3397 - acc: 0.8314\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.3586 - acc: 0.8429\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3336 - acc: 0.8391\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3267 - acc: 0.8314\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.3176 - acc: 0.8582\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3114 - acc: 0.8659\n",
      "131/131 [==============================] - 0s 7us/step\n",
      "261/261 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.7709923786971405, total=   2.6s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.6864 - acc: 0.6107\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 38us/step - loss: 0.6659 - acc: 0.6794\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.6290 - acc: 0.7595\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.6059 - acc: 0.7405\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.5843 - acc: 0.7443\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.5639 - acc: 0.7595\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 63us/step - loss: 0.5525 - acc: 0.7557\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.5374 - acc: 0.7748\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.5256 - acc: 0.7748\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.5182 - acc: 0.7595\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.5002 - acc: 0.7786\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.4937 - acc: 0.7710\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.4903 - acc: 0.7672\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4787 - acc: 0.7939\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4726 - acc: 0.7710\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.4575 - acc: 0.8092\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.4548 - acc: 0.7939\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.4557 - acc: 0.7977\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.4404 - acc: 0.7939\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4470 - acc: 0.8168\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4368 - acc: 0.8092\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.4245 - acc: 0.8092\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.4241 - acc: 0.8321\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.4164 - acc: 0.8282\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4106 - acc: 0.8130\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 86us/step - loss: 0.4123 - acc: 0.8168\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 38us/step - loss: 0.4232 - acc: 0.8168\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.4065 - acc: 0.8168\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.4001 - acc: 0.8282\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.3954 - acc: 0.8168\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.3996 - acc: 0.8282\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.3984 - acc: 0.8206\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.3913 - acc: 0.8359\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.4008 - acc: 0.8282\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3917 - acc: 0.8321\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.3888 - acc: 0.8321\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.4042 - acc: 0.8359\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 170us/step - loss: 0.3929 - acc: 0.8321\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3897 - acc: 0.8282\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3838 - acc: 0.8359\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.3689 - acc: 0.8473\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 128us/step - loss: 0.3661 - acc: 0.8397\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 121us/step - loss: 0.3659 - acc: 0.8321\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.3940 - acc: 0.8130\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.3657 - acc: 0.8550\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3679 - acc: 0.8435\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.3677 - acc: 0.8397\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.3653 - acc: 0.8435\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3556 - acc: 0.8550\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.3594 - acc: 0.8550\n",
      "130/130 [==============================] - 0s 19us/step\n",
      "262/262 [==============================] - 0s 33us/step\n",
      "[CV]  batch_size=20, epochs=50, score=0.8076923122772803, total=   2.6s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.6829 - acc: 0.6820\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.6522 - acc: 0.7356\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.6130 - acc: 0.7816\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.5741 - acc: 0.8046\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.5447 - acc: 0.8123\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.5191 - acc: 0.8238\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.5002 - acc: 0.8238\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 167us/step - loss: 0.4873 - acc: 0.8238\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.4745 - acc: 0.8314\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.4710 - acc: 0.8161\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.4547 - acc: 0.8199\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.4505 - acc: 0.8352\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.4361 - acc: 0.8352\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.4303 - acc: 0.8352\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.4225 - acc: 0.8467\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4128 - acc: 0.8506\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.4115 - acc: 0.8352\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.4134 - acc: 0.8238\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3956 - acc: 0.8582\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3909 - acc: 0.8467\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3810 - acc: 0.8621\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3805 - acc: 0.8506\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3733 - acc: 0.8544\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3727 - acc: 0.8621\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.3581 - acc: 0.8736\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3555 - acc: 0.8659\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3582 - acc: 0.8621\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3695 - acc: 0.8506\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3587 - acc: 0.8544\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3392 - acc: 0.8506\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3488 - acc: 0.8467\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3599 - acc: 0.8391\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3378 - acc: 0.8506\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3196 - acc: 0.8659\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3101 - acc: 0.8774\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3286 - acc: 0.8506\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3421 - acc: 0.8429\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3257 - acc: 0.8697\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3191 - acc: 0.8621\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3085 - acc: 0.8697\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3042 - acc: 0.8774\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2973 - acc: 0.8851\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2924 - acc: 0.8889\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.2899 - acc: 0.8966\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.2812 - acc: 0.9004\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2813 - acc: 0.8851\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2784 - acc: 0.8812\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2970 - acc: 0.8851\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3494 - acc: 0.8621\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3312 - acc: 0.8506\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3035 - acc: 0.8697\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2781 - acc: 0.8736\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2730 - acc: 0.8736\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.2675 - acc: 0.8659\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.2651 - acc: 0.8851\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 86us/step - loss: 0.2640 - acc: 0.9004\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 105us/step - loss: 0.2620 - acc: 0.9004\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2601 - acc: 0.8889\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.2564 - acc: 0.9042\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2562 - acc: 0.8966\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.2563 - acc: 0.8966\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.2573 - acc: 0.8889\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.2525 - acc: 0.9042\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.2898 - acc: 0.8774\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.2829 - acc: 0.8851\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2632 - acc: 0.8889\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.2525 - acc: 0.8927\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2960 - acc: 0.8697\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.2681 - acc: 0.8851\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.2494 - acc: 0.9042\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.2520 - acc: 0.9042\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.2659 - acc: 0.8927\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2689 - acc: 0.8889\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2624 - acc: 0.8966\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.2583 - acc: 0.9004\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.2908 - acc: 0.8966\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.2869 - acc: 0.9004\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.2715 - acc: 0.9195\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2638 - acc: 0.9157\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.2515 - acc: 0.9195\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.2452 - acc: 0.9119\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2388 - acc: 0.9119\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2556 - acc: 0.9157\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.2531 - acc: 0.9042\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.2402 - acc: 0.9080\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.2336 - acc: 0.9195\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.2567 - acc: 0.9004\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.2465 - acc: 0.9004\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2376 - acc: 0.9119\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2305 - acc: 0.9157\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2326 - acc: 0.9157\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.2280 - acc: 0.9157\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2269 - acc: 0.9157\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.2425 - acc: 0.8966\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2507 - acc: 0.9004\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.2395 - acc: 0.9042\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2305 - acc: 0.9195\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.2623 - acc: 0.9080\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2587 - acc: 0.9042\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2638 - acc: 0.9004\n",
      "131/131 [==============================] - 0s 23us/step\n",
      "261/261 [==============================] - 0s 12us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7557251901571987, total=   4.3s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.6763 - acc: 0.6284\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.6203 - acc: 0.6552\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.5354 - acc: 0.6552\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.5034 - acc: 0.6552\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.4914 - acc: 0.6552\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.4832 - acc: 0.6552\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4755 - acc: 0.7739\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.4685 - acc: 0.7931\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.4598 - acc: 0.8046\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4558 - acc: 0.8084\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.4513 - acc: 0.8046\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.4444 - acc: 0.8046\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.4387 - acc: 0.8199\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.4336 - acc: 0.8123\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.4310 - acc: 0.8161\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.4289 - acc: 0.8199\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.4281 - acc: 0.8161\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.4248 - acc: 0.8238\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.4176 - acc: 0.8276\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4142 - acc: 0.8238\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.4192 - acc: 0.8123\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.4070 - acc: 0.8314\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4024 - acc: 0.8391\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3993 - acc: 0.8276\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.3955 - acc: 0.8314\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3876 - acc: 0.8467\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 112us/step - loss: 0.3973 - acc: 0.8314\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.3998 - acc: 0.8391\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.4049 - acc: 0.8238\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 34us/step - loss: 0.3940 - acc: 0.8314\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3860 - acc: 0.8467\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3758 - acc: 0.8506\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3711 - acc: 0.8544\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3706 - acc: 0.8697\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3661 - acc: 0.8621\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 61us/step - loss: 0.3602 - acc: 0.8621\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3538 - acc: 0.8659\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3531 - acc: 0.8621\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.3493 - acc: 0.8659\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.3534 - acc: 0.8544\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 171us/step - loss: 0.3782 - acc: 0.8544\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3734 - acc: 0.8544\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3581 - acc: 0.8544\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3502 - acc: 0.8582\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3474 - acc: 0.8621\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3385 - acc: 0.8812\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3377 - acc: 0.8774\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3307 - acc: 0.8736\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3252 - acc: 0.8812\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3266 - acc: 0.8812\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3228 - acc: 0.8812\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3189 - acc: 0.8774\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.3192 - acc: 0.8774\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3304 - acc: 0.8659\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3238 - acc: 0.8697\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3183 - acc: 0.8774\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.3109 - acc: 0.8812\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3300 - acc: 0.8659\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 158us/step - loss: 0.3186 - acc: 0.8851\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3092 - acc: 0.8889\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3091 - acc: 0.8851\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.3041 - acc: 0.8927\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3102 - acc: 0.8966\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3054 - acc: 0.8966\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3058 - acc: 0.8966\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3064 - acc: 0.8889\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3272 - acc: 0.8621\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.3436 - acc: 0.8429\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3135 - acc: 0.8659\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.3066 - acc: 0.8889\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3011 - acc: 0.8927\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.2963 - acc: 0.9004\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2935 - acc: 0.9004\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3210 - acc: 0.8774\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3297 - acc: 0.8736\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 120us/step - loss: 0.3017 - acc: 0.8966\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.2947 - acc: 0.9080\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.2967 - acc: 0.9042\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2907 - acc: 0.9080\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2890 - acc: 0.9080\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.2888 - acc: 0.9080\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 144us/step - loss: 0.3057 - acc: 0.8774\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3223 - acc: 0.8736\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3170 - acc: 0.8812\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3136 - acc: 0.8774\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.2995 - acc: 0.8889\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.2876 - acc: 0.9004\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2881 - acc: 0.9080\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2838 - acc: 0.9119\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.2847 - acc: 0.9042\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.2827 - acc: 0.9119\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2813 - acc: 0.9119\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.2955 - acc: 0.9042\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 110us/step - loss: 0.2816 - acc: 0.9080\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.2835 - acc: 0.9080\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3261 - acc: 0.8774\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3100 - acc: 0.8851\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 0s 132us/step - loss: 0.2921 - acc: 0.8927\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.2823 - acc: 0.8966\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.2793 - acc: 0.9042\n",
      "131/131 [==============================] - 0s 19us/step\n",
      "261/261 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7786259510134923, total=   4.1s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.6725 - acc: 0.6374\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 0s 44us/step - loss: 0.5995 - acc: 0.6794\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.5020 - acc: 0.7481\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.4822 - acc: 0.7481\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 0s 76us/step - loss: 0.4720 - acc: 0.7557\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.4637 - acc: 0.7595\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4617 - acc: 0.7634\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.4601 - acc: 0.7595\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4584 - acc: 0.7557\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.4543 - acc: 0.7710\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.4547 - acc: 0.7672\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.4483 - acc: 0.7519\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4415 - acc: 0.7672\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.4480 - acc: 0.7710\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - 0s 142us/step - loss: 0.4462 - acc: 0.7786\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 90us/step - loss: 0.4358 - acc: 0.7786\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.4332 - acc: 0.7863\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.4288 - acc: 0.7901\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.4304 - acc: 0.7939\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - 0s 159us/step - loss: 0.4233 - acc: 0.7824\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4218 - acc: 0.7977\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4153 - acc: 0.8015\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.4169 - acc: 0.7977\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.4117 - acc: 0.7939\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.4081 - acc: 0.8092\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4145 - acc: 0.7977\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - 0s 151us/step - loss: 0.4052 - acc: 0.7977\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - 0s 38us/step - loss: 0.4079 - acc: 0.7977\n",
      "Epoch 29/100\n",
      "262/262 [==============================] - 0s 159us/step - loss: 0.4103 - acc: 0.7977\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.4073 - acc: 0.7977\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.3972 - acc: 0.7939\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8206\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.3980 - acc: 0.8206\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - 0s 36us/step - loss: 0.3902 - acc: 0.8092\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3935 - acc: 0.8168\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3871 - acc: 0.8168\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.3802 - acc: 0.8321\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - 0s 35us/step - loss: 0.3762 - acc: 0.8359\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3721 - acc: 0.8282\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3760 - acc: 0.8206\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - 0s 144us/step - loss: 0.3674 - acc: 0.8321\n",
      "Epoch 42/100\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.3691 - acc: 0.8397\n",
      "Epoch 43/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3643 - acc: 0.8282\n",
      "Epoch 44/100\n",
      "262/262 [==============================] - 0s 144us/step - loss: 0.3648 - acc: 0.8435\n",
      "Epoch 45/100\n",
      "262/262 [==============================] - 0s 153us/step - loss: 0.3715 - acc: 0.8321\n",
      "Epoch 46/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3670 - acc: 0.8473\n",
      "Epoch 47/100\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.3595 - acc: 0.8473\n",
      "Epoch 48/100\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.3577 - acc: 0.8511\n",
      "Epoch 49/100\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3559 - acc: 0.8473\n",
      "Epoch 50/100\n",
      "262/262 [==============================] - 0s 123us/step - loss: 0.3543 - acc: 0.8359\n",
      "Epoch 51/100\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.3470 - acc: 0.8511\n",
      "Epoch 52/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3476 - acc: 0.8435\n",
      "Epoch 53/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.3588 - acc: 0.8626\n",
      "Epoch 54/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3425 - acc: 0.8588\n",
      "Epoch 55/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.3556 - acc: 0.8550\n",
      "Epoch 56/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.3673 - acc: 0.8206\n",
      "Epoch 57/100\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.3477 - acc: 0.8435\n",
      "Epoch 58/100\n",
      "262/262 [==============================] - 0s 100us/step - loss: 0.3411 - acc: 0.8435\n",
      "Epoch 59/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.3363 - acc: 0.8511\n",
      "Epoch 60/100\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.3349 - acc: 0.8397\n",
      "Epoch 61/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3388 - acc: 0.8359\n",
      "Epoch 62/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3343 - acc: 0.8511\n",
      "Epoch 63/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.3343 - acc: 0.8473\n",
      "Epoch 64/100\n",
      "262/262 [==============================] - 0s 63us/step - loss: 0.3276 - acc: 0.8664\n",
      "Epoch 65/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.3207 - acc: 0.8779\n",
      "Epoch 66/100\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3399 - acc: 0.8664\n",
      "Epoch 67/100\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.3323 - acc: 0.8626\n",
      "Epoch 68/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3658 - acc: 0.8397\n",
      "Epoch 69/100\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.3518 - acc: 0.8511\n",
      "Epoch 70/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3467 - acc: 0.8511\n",
      "Epoch 71/100\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.3282 - acc: 0.8588\n",
      "Epoch 72/100\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.3278 - acc: 0.8473\n",
      "Epoch 73/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3215 - acc: 0.8702\n",
      "Epoch 74/100\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3124 - acc: 0.8817\n",
      "Epoch 75/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.3142 - acc: 0.8779\n",
      "Epoch 76/100\n",
      "262/262 [==============================] - 0s 100us/step - loss: 0.3264 - acc: 0.8550\n",
      "Epoch 77/100\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.3276 - acc: 0.8511\n",
      "Epoch 78/100\n",
      "262/262 [==============================] - 0s 113us/step - loss: 0.3184 - acc: 0.8626\n",
      "Epoch 79/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.3135 - acc: 0.8740\n",
      "Epoch 80/100\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.3145 - acc: 0.8817\n",
      "Epoch 81/100\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.3107 - acc: 0.8893\n",
      "Epoch 82/100\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3540 - acc: 0.8511\n",
      "Epoch 83/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.3132 - acc: 0.8511\n",
      "Epoch 84/100\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3133 - acc: 0.8588\n",
      "Epoch 85/100\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.3020 - acc: 0.8855\n",
      "Epoch 86/100\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3007 - acc: 0.8855\n",
      "Epoch 87/100\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.2977 - acc: 0.8855\n",
      "Epoch 88/100\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.2973 - acc: 0.8740\n",
      "Epoch 89/100\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.2970 - acc: 0.8855\n",
      "Epoch 90/100\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.2938 - acc: 0.8931\n",
      "Epoch 91/100\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.3032 - acc: 0.8702\n",
      "Epoch 92/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3385 - acc: 0.8473\n",
      "Epoch 93/100\n",
      "262/262 [==============================] - 0s 119us/step - loss: 0.3131 - acc: 0.8779\n",
      "Epoch 94/100\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.3059 - acc: 0.8473\n",
      "Epoch 95/100\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.3011 - acc: 0.8969\n",
      "Epoch 96/100\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.2927 - acc: 0.8931\n",
      "Epoch 97/100\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.2893 - acc: 0.8931\n",
      "Epoch 98/100\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.2886 - acc: 0.9046\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 99us/step - loss: 0.2860 - acc: 0.8969\n",
      "Epoch 100/100\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.2868 - acc: 0.8931\n",
      "130/130 [==============================] - 0s 11us/step\n",
      "262/262 [==============================] - 0s 8us/step\n",
      "[CV]  batch_size=20, epochs=100, score=0.7923077023946322, total=   4.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 15us/step - loss: 0.6754 - acc: 0.6667\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 40us/step - loss: 0.6104 - acc: 0.7778\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.5156 - acc: 0.7931\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 48us/step - loss: 0.4385 - acc: 0.7969\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4086 - acc: 0.7931\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3981 - acc: 0.7969\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3908 - acc: 0.8123\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.3809 - acc: 0.8161\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.3750 - acc: 0.8276\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3715 - acc: 0.8352\n",
      "131/131 [==============================] - 0s 11us/step\n",
      "261/261 [==============================] - 0s 8us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.7175572464484294, total=   1.5s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.6811 - acc: 0.6207\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.6329 - acc: 0.7280\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.5599 - acc: 0.7625\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 27us/step - loss: 0.4877 - acc: 0.7816\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 64us/step - loss: 0.4571 - acc: 0.7893\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 160us/step - loss: 0.4437 - acc: 0.7893\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.4360 - acc: 0.7931\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.4315 - acc: 0.7969\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.4278 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.4272 - acc: 0.7893\n",
      "131/131 [==============================] - 0s 8us/step\n",
      "261/261 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.7633587809009407, total=   1.3s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "262/262 [==============================] - 0s 25us/step - loss: 0.6841 - acc: 0.6221\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 29us/step - loss: 0.6518 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 36us/step - loss: 0.6013 - acc: 0.6527\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 63us/step - loss: 0.5499 - acc: 0.6527\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 31us/step - loss: 0.5239 - acc: 0.6527\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.5156 - acc: 0.6527\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 57us/step - loss: 0.5080 - acc: 0.6527\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.5026 - acc: 0.6527\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 57us/step - loss: 0.4976 - acc: 0.6527\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4946 - acc: 0.6527\n",
      "130/130 [==============================] - 0s 11us/step\n",
      "262/262 [==============================] - 0s 11us/step\n",
      "[CV]  batch_size=40, epochs=10, score=0.699999988079071, total=   1.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 17us/step - loss: 0.6688 - acc: 0.6513\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.5790 - acc: 0.7241\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.4898 - acc: 0.7701\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 50us/step - loss: 0.4485 - acc: 0.7778\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.4202 - acc: 0.7931\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.3996 - acc: 0.8084\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3898 - acc: 0.8161\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3840 - acc: 0.8123\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 48us/step - loss: 0.3794 - acc: 0.8161\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3743 - acc: 0.8161\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.3701 - acc: 0.8314\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3669 - acc: 0.8314\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.3623 - acc: 0.8276\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3589 - acc: 0.8352\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3558 - acc: 0.8429\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3536 - acc: 0.8467\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 48us/step - loss: 0.3494 - acc: 0.8506\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3481 - acc: 0.8506\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3453 - acc: 0.8391\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.3421 - acc: 0.8391\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3388 - acc: 0.8467\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3368 - acc: 0.8506\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.3339 - acc: 0.8429\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.3330 - acc: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3326 - acc: 0.8544\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3277 - acc: 0.8544\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3235 - acc: 0.8621\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3217 - acc: 0.8621\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.3214 - acc: 0.8467\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3206 - acc: 0.8467\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 31us/step - loss: 0.3165 - acc: 0.8506\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3154 - acc: 0.8621\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3111 - acc: 0.8544\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3108 - acc: 0.8467\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3094 - acc: 0.8621\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3074 - acc: 0.8659\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3076 - acc: 0.8621\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 31us/step - loss: 0.3047 - acc: 0.8582\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3020 - acc: 0.8659\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.3009 - acc: 0.8697\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.2986 - acc: 0.8736\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.2983 - acc: 0.8659\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 35us/step - loss: 0.2969 - acc: 0.8659\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.2972 - acc: 0.8659\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.2965 - acc: 0.8697\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 17us/step - loss: 0.2958 - acc: 0.8812\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 42us/step - loss: 0.2935 - acc: 0.8774\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2905 - acc: 0.8774\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2929 - acc: 0.8621\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.2907 - acc: 0.8697\n",
      "131/131 [==============================] - 0s 8us/step\n",
      "261/261 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.7022900754258833, total=   2.1s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 42us/step - loss: 0.6819 - acc: 0.7510\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.6401 - acc: 0.7586\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.5727 - acc: 0.7931\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.4981 - acc: 0.7778\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.4563 - acc: 0.7739\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.4460 - acc: 0.7778\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.4386 - acc: 0.7893\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4308 - acc: 0.8008\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.4249 - acc: 0.8123\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.4283 - acc: 0.8008\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.4177 - acc: 0.7969\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.4132 - acc: 0.8123\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.4071 - acc: 0.8123\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.4042 - acc: 0.8123\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 50us/step - loss: 0.4000 - acc: 0.8199\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3976 - acc: 0.8238\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3933 - acc: 0.8314\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.3897 - acc: 0.8352\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3869 - acc: 0.8276\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.3845 - acc: 0.8314\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 40us/step - loss: 0.3811 - acc: 0.8352\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3806 - acc: 0.8352\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3797 - acc: 0.8429\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3783 - acc: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3730 - acc: 0.8506\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3734 - acc: 0.8429\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 27us/step - loss: 0.3699 - acc: 0.8582\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3707 - acc: 0.8467\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3669 - acc: 0.8544\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3672 - acc: 0.8544\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3638 - acc: 0.8582\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.3655 - acc: 0.8506\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3630 - acc: 0.8467\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.3609 - acc: 0.8506\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3601 - acc: 0.8467\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3584 - acc: 0.8467\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3601 - acc: 0.8467\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.3603 - acc: 0.8467\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3556 - acc: 0.8467\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3493 - acc: 0.8506\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3493 - acc: 0.8467\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3467 - acc: 0.8544\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.3495 - acc: 0.8467\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.3497 - acc: 0.8429\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.3441 - acc: 0.8467\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3433 - acc: 0.8659\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.3384 - acc: 0.8621\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.3431 - acc: 0.8544\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.3411 - acc: 0.8506\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3372 - acc: 0.8544\n",
      "131/131 [==============================] - 0s 8us/step\n",
      "261/261 [==============================] - 0s 8us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.7786259683033893, total=   2.4s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 0s 21us/step - loss: 0.6769 - acc: 0.6489\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 31us/step - loss: 0.6276 - acc: 0.6489\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 19us/step - loss: 0.5431 - acc: 0.7176\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.5005 - acc: 0.7557\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 41us/step - loss: 0.4800 - acc: 0.7481\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.4747 - acc: 0.7672\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.4672 - acc: 0.7748\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 55us/step - loss: 0.4618 - acc: 0.7710\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 19us/step - loss: 0.4601 - acc: 0.7710\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.4580 - acc: 0.7748\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 23us/step - loss: 0.4560 - acc: 0.7748\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.4536 - acc: 0.7748\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 33us/step - loss: 0.4533 - acc: 0.7672\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.4487 - acc: 0.7710\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 36us/step - loss: 0.4475 - acc: 0.7748\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.4450 - acc: 0.7710\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 38us/step - loss: 0.4432 - acc: 0.7748\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4462 - acc: 0.7786\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4366 - acc: 0.7901\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 44us/step - loss: 0.4315 - acc: 0.7939\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.4301 - acc: 0.7901\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 59us/step - loss: 0.4272 - acc: 0.7977\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 44us/step - loss: 0.4248 - acc: 0.7901\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 55us/step - loss: 0.4228 - acc: 0.7977\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 21us/step - loss: 0.4194 - acc: 0.7977\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.4153 - acc: 0.8092\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 29us/step - loss: 0.4122 - acc: 0.8015\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.4097 - acc: 0.8015\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.4099 - acc: 0.8015\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.4042 - acc: 0.8092\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4032 - acc: 0.8092\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4000 - acc: 0.8092\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3964 - acc: 0.8130\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.3951 - acc: 0.8130\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3937 - acc: 0.8206\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.3920 - acc: 0.8168\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.3918 - acc: 0.8130\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 73us/step - loss: 0.3885 - acc: 0.8282\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 29us/step - loss: 0.3853 - acc: 0.8244\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3863 - acc: 0.8130\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3815 - acc: 0.8206\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.3811 - acc: 0.8244\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.3789 - acc: 0.8282\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 101us/step - loss: 0.3818 - acc: 0.8282\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 21us/step - loss: 0.3778 - acc: 0.8282\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.3750 - acc: 0.8321\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3725 - acc: 0.8397\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 25us/step - loss: 0.3748 - acc: 0.8397\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.3682 - acc: 0.8435\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3670 - acc: 0.8473\n",
      "130/130 [==============================] - 0s 7us/step\n",
      "262/262 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=40, epochs=50, score=0.8461538369839008, total=   2.4s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 17us/step - loss: 0.6761 - acc: 0.6743\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.6189 - acc: 0.6973\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.5401 - acc: 0.6973\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.4767 - acc: 0.6973\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4460 - acc: 0.7050\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.4256 - acc: 0.7739\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.4047 - acc: 0.8008\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3860 - acc: 0.8199\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.3797 - acc: 0.8276\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3751 - acc: 0.8276\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.3680 - acc: 0.8276\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3625 - acc: 0.8352\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 31us/step - loss: 0.3579 - acc: 0.8391\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3532 - acc: 0.8429\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.3484 - acc: 0.8391\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3453 - acc: 0.8391\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3436 - acc: 0.8429\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3403 - acc: 0.8429\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.3388 - acc: 0.8391\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3347 - acc: 0.8429\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3322 - acc: 0.8391\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3300 - acc: 0.8429\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3277 - acc: 0.8429\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3246 - acc: 0.8467\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3219 - acc: 0.8391\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3207 - acc: 0.8429\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3178 - acc: 0.8506\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.3152 - acc: 0.8544\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3145 - acc: 0.8506\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.3129 - acc: 0.8544\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3112 - acc: 0.8544\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3088 - acc: 0.8659\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.3069 - acc: 0.8659\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3052 - acc: 0.8621\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.3036 - acc: 0.8659\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3038 - acc: 0.8582\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3013 - acc: 0.8659\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3038 - acc: 0.8582\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2991 - acc: 0.8774\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.3002 - acc: 0.8621\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.2973 - acc: 0.8659\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.2994 - acc: 0.8621\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2994 - acc: 0.8621\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.2983 - acc: 0.8697\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2981 - acc: 0.8736\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2960 - acc: 0.8736\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2952 - acc: 0.8697\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2981 - acc: 0.8621\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.2968 - acc: 0.8582\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2928 - acc: 0.8697\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.2936 - acc: 0.8582\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3028 - acc: 0.8582\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 44us/step - loss: 0.2934 - acc: 0.8697\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.2958 - acc: 0.8736\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2929 - acc: 0.8659\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.2889 - acc: 0.8659\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.2950 - acc: 0.8697\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2899 - acc: 0.8697\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.2890 - acc: 0.8659\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.2881 - acc: 0.8659\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.2906 - acc: 0.8621\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.2850 - acc: 0.8697\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.2864 - acc: 0.8659\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.2882 - acc: 0.8697\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2862 - acc: 0.8697\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2848 - acc: 0.8697\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.2837 - acc: 0.8621\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.2847 - acc: 0.8621\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2827 - acc: 0.8621\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.2820 - acc: 0.8582\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.2820 - acc: 0.8582\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.2828 - acc: 0.8582\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.2821 - acc: 0.8621\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2835 - acc: 0.8621\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.2831 - acc: 0.8621\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2831 - acc: 0.8582\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.2810 - acc: 0.8582\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.2808 - acc: 0.8582\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.2786 - acc: 0.8697\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.2790 - acc: 0.8621\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.2793 - acc: 0.8621\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2797 - acc: 0.8582\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.2815 - acc: 0.8544\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2798 - acc: 0.8659\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.2771 - acc: 0.8697\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 70us/step - loss: 0.2784 - acc: 0.8621\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.2770 - acc: 0.8621\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2737 - acc: 0.8621\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.2726 - acc: 0.8621\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2790 - acc: 0.8544\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 117us/step - loss: 0.2752 - acc: 0.8506\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.2706 - acc: 0.8621\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.2717 - acc: 0.8621\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.2755 - acc: 0.8506\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.2702 - acc: 0.8582\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 62us/step - loss: 0.2713 - acc: 0.8582\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.2688 - acc: 0.8659\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.3348 - acc: 0.825 - 0s 54us/step - loss: 0.2714 - acc: 0.8582\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 36us/step - loss: 0.2675 - acc: 0.8659\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2701 - acc: 0.8621\n",
      "131/131 [==============================] - 0s 11us/step\n",
      "261/261 [==============================] - 0s 10us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.7022900936257748, total=   3.1s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.6819 - acc: 0.6054\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.6348 - acc: 0.7280\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.5609 - acc: 0.7739\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.4892 - acc: 0.7739\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4531 - acc: 0.7931\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 0s 60us/step - loss: 0.4525 - acc: 0.7816\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 0s 34us/step - loss: 0.4429 - acc: 0.7816\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.4328 - acc: 0.7931\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4292 - acc: 0.7969\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 0s 36us/step - loss: 0.4246 - acc: 0.7969\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4220 - acc: 0.7931\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.4177 - acc: 0.8008\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.4171 - acc: 0.8199\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.4125 - acc: 0.8161\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 0s 50us/step - loss: 0.4109 - acc: 0.8084\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.4083 - acc: 0.8199\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 0s 37us/step - loss: 0.4041 - acc: 0.8238\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3991 - acc: 0.8276\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.3977 - acc: 0.8238\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3943 - acc: 0.8276\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.3921 - acc: 0.8314\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3873 - acc: 0.8276\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3849 - acc: 0.8276\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3825 - acc: 0.8352\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3779 - acc: 0.8467\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3747 - acc: 0.8467\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 0s 25us/step - loss: 0.3718 - acc: 0.8467\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3721 - acc: 0.8429\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3641 - acc: 0.8506\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3637 - acc: 0.8467\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3597 - acc: 0.8506\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.3593 - acc: 0.8467\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 69us/step - loss: 0.3573 - acc: 0.8506\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3546 - acc: 0.8506\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3541 - acc: 0.8544\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3521 - acc: 0.8506\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3515 - acc: 0.8582\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3491 - acc: 0.8429\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.3441 - acc: 0.8506\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3463 - acc: 0.8621\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.3449 - acc: 0.8544\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3392 - acc: 0.8467\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 0s 36us/step - loss: 0.3413 - acc: 0.8467\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.3385 - acc: 0.8621\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 0s 27us/step - loss: 0.3353 - acc: 0.8697\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.3286 - acc: 0.8621\n",
      "Epoch 47/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.3328 - acc: 0.8506\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3312 - acc: 0.8659\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 0s 36us/step - loss: 0.3226 - acc: 0.8812\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3209 - acc: 0.8659\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3226 - acc: 0.8621\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3179 - acc: 0.8582\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 0s 31us/step - loss: 0.3168 - acc: 0.8621\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3186 - acc: 0.8544\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3144 - acc: 0.8506\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3097 - acc: 0.8582\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 0s 27us/step - loss: 0.3076 - acc: 0.8697\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3082 - acc: 0.8621\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 0s 23us/step - loss: 0.3096 - acc: 0.8621\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3046 - acc: 0.8621\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.3032 - acc: 0.8621\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.3022 - acc: 0.8774\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.2993 - acc: 0.8736\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2979 - acc: 0.8697\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 0s 58us/step - loss: 0.2941 - acc: 0.8659\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.2927 - acc: 0.8697\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 0s 42us/step - loss: 0.2902 - acc: 0.8659\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.2947 - acc: 0.8697\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.3009 - acc: 0.8736\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.2801 - acc: 0.8774\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.2873 - acc: 0.8659\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.2879 - acc: 0.8736\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 0s 44us/step - loss: 0.2758 - acc: 0.8889\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 0s 81us/step - loss: 0.2762 - acc: 0.8697\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2707 - acc: 0.8812\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2777 - acc: 0.8774\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 0s 52us/step - loss: 0.2745 - acc: 0.8697\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.2621 - acc: 0.8851\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2595 - acc: 0.8812\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2567 - acc: 0.8774\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2538 - acc: 0.8889\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.2530 - acc: 0.8927\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 0s 75us/step - loss: 0.2490 - acc: 0.8889\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 0s 33us/step - loss: 0.2462 - acc: 0.9004\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.2470 - acc: 0.8889\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2542 - acc: 0.9004\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2451 - acc: 0.9004\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.2516 - acc: 0.8889\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.2434 - acc: 0.8889\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.2480 - acc: 0.9042\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.2332 - acc: 0.9042\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2362 - acc: 0.8966\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.2308 - acc: 0.8966\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.2308 - acc: 0.9004\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 0s 21us/step - loss: 0.2302 - acc: 0.9080\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 0s 40us/step - loss: 0.2289 - acc: 0.8889\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 0s 29us/step - loss: 0.2235 - acc: 0.9080\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 0s 19us/step - loss: 0.2237 - acc: 0.9234\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 0s 35us/step - loss: 0.2202 - acc: 0.9042\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 0s 17us/step - loss: 0.2191 - acc: 0.9042\n",
      "131/131 [==============================] - 0s 8us/step\n",
      "261/261 [==============================] - 0s 8us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.7557251903846973, total=   3.2s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "Epoch 1/100\n",
      "262/262 [==============================] - 0s 19us/step - loss: 0.6763 - acc: 0.6527\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 0s 36us/step - loss: 0.6278 - acc: 0.6679\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 0s 31us/step - loss: 0.5414 - acc: 0.7328\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.4941 - acc: 0.7557\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 0s 23us/step - loss: 0.4841 - acc: 0.7519\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.4710 - acc: 0.7672\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 0s 17us/step - loss: 0.4711 - acc: 0.7786\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - 0s 15us/step - loss: 0.4632 - acc: 0.7786\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4616 - acc: 0.7519\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - 0s 31us/step - loss: 0.4619 - acc: 0.7634\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4538 - acc: 0.7748\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 0s 40us/step - loss: 0.4519 - acc: 0.7634\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 0s 48us/step - loss: 0.4508 - acc: 0.7634\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 63us/step - loss: 0.4465 - acc: 0.7824\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.4450 - acc: 0.7748\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - 0s 31us/step - loss: 0.4423 - acc: 0.7863\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.4399 - acc: 0.7786\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - 0s 23us/step - loss: 0.4387 - acc: 0.7748\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.4348 - acc: 0.7863\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - 0s 48us/step - loss: 0.4349 - acc: 0.7863\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.4335 - acc: 0.7824\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4260 - acc: 0.7786\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.4274 - acc: 0.7901\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - 0s 48us/step - loss: 0.4269 - acc: 0.7939\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4211 - acc: 0.7901\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4206 - acc: 0.7901\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.4161 - acc: 0.7863\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.4149 - acc: 0.7786\n",
      "Epoch 29/100\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.4143 - acc: 0.7748\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.4122 - acc: 0.7748\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.4114 - acc: 0.7824\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - 0s 36us/step - loss: 0.4089 - acc: 0.7824\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4075 - acc: 0.7863\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.4069 - acc: 0.7939\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - 0s 117us/step - loss: 0.4028 - acc: 0.7901\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.4043 - acc: 0.7939\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3979 - acc: 0.7901\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - 0s 115us/step - loss: 0.4001 - acc: 0.7939\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.3946 - acc: 0.8015\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3940 - acc: 0.7824\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.3901 - acc: 0.7939\n",
      "Epoch 42/100\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.3901 - acc: 0.7939\n",
      "Epoch 43/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.3921 - acc: 0.7939\n",
      "Epoch 44/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3843 - acc: 0.8130\n",
      "Epoch 45/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3839 - acc: 0.8015\n",
      "Epoch 46/100\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.3815 - acc: 0.7939\n",
      "Epoch 47/100\n",
      "262/262 [==============================] - 0s 55us/step - loss: 0.3831 - acc: 0.8130\n",
      "Epoch 48/100\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3776 - acc: 0.8168\n",
      "Epoch 49/100\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.3747 - acc: 0.8092\n",
      "Epoch 50/100\n",
      "262/262 [==============================] - 0s 52us/step - loss: 0.3736 - acc: 0.8053\n",
      "Epoch 51/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3714 - acc: 0.8168\n",
      "Epoch 52/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3729 - acc: 0.8168\n",
      "Epoch 53/100\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.3677 - acc: 0.8206\n",
      "Epoch 54/100\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.3670 - acc: 0.8206\n",
      "Epoch 55/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3671 - acc: 0.8282\n",
      "Epoch 56/100\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3683 - acc: 0.8206\n",
      "Epoch 57/100\n",
      "262/262 [==============================] - 0s 63us/step - loss: 0.3648 - acc: 0.8130\n",
      "Epoch 58/100\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3643 - acc: 0.8130\n",
      "Epoch 59/100\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3627 - acc: 0.8206\n",
      "Epoch 60/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.3593 - acc: 0.8206\n",
      "Epoch 61/100\n",
      "262/262 [==============================] - 0s 44us/step - loss: 0.3605 - acc: 0.8168\n",
      "Epoch 62/100\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.3581 - acc: 0.8321\n",
      "Epoch 63/100\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.3557 - acc: 0.8359\n",
      "Epoch 64/100\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3589 - acc: 0.8244\n",
      "Epoch 65/100\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.3547 - acc: 0.8321\n",
      "Epoch 66/100\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.3580 - acc: 0.8168\n",
      "Epoch 67/100\n",
      "262/262 [==============================] - 0s 40us/step - loss: 0.3495 - acc: 0.8244\n",
      "Epoch 68/100\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.3524 - acc: 0.8397\n",
      "Epoch 69/100\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.3483 - acc: 0.8321\n",
      "Epoch 70/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3494 - acc: 0.8244\n",
      "Epoch 71/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3472 - acc: 0.8359\n",
      "Epoch 72/100\n",
      "262/262 [==============================] - 0s 44us/step - loss: 0.3484 - acc: 0.8435\n",
      "Epoch 73/100\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3488 - acc: 0.8282\n",
      "Epoch 74/100\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.3425 - acc: 0.8244\n",
      "Epoch 75/100\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.3467 - acc: 0.8321\n",
      "Epoch 76/100\n",
      "262/262 [==============================] - 0s 33us/step - loss: 0.3405 - acc: 0.8359\n",
      "Epoch 77/100\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.3413 - acc: 0.8359\n",
      "Epoch 78/100\n",
      "262/262 [==============================] - 0s 34us/step - loss: 0.3409 - acc: 0.8359\n",
      "Epoch 79/100\n",
      "262/262 [==============================] - 0s 73us/step - loss: 0.3373 - acc: 0.8473\n",
      "Epoch 80/100\n",
      "262/262 [==============================] - 0s 33us/step - loss: 0.3354 - acc: 0.8435\n",
      "Epoch 81/100\n",
      "262/262 [==============================] - 0s 75us/step - loss: 0.3357 - acc: 0.8550\n",
      "Epoch 82/100\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.3354 - acc: 0.8511\n",
      "Epoch 83/100\n",
      "262/262 [==============================] - 0s 67us/step - loss: 0.3336 - acc: 0.8588\n",
      "Epoch 84/100\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.3348 - acc: 0.8435\n",
      "Epoch 85/100\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3302 - acc: 0.8550\n",
      "Epoch 86/100\n",
      "262/262 [==============================] - 0s 54us/step - loss: 0.3377 - acc: 0.8511\n",
      "Epoch 87/100\n",
      "262/262 [==============================] - 0s 59us/step - loss: 0.3296 - acc: 0.8473\n",
      "Epoch 88/100\n",
      "262/262 [==============================] - 0s 52us/step - loss: 0.3319 - acc: 0.8550\n",
      "Epoch 89/100\n",
      "262/262 [==============================] - 0s 63us/step - loss: 0.3300 - acc: 0.8588\n",
      "Epoch 90/100\n",
      "262/262 [==============================] - 0s 27us/step - loss: 0.3268 - acc: 0.8550\n",
      "Epoch 91/100\n",
      "262/262 [==============================] - 0s 71us/step - loss: 0.3266 - acc: 0.8550\n",
      "Epoch 92/100\n",
      "262/262 [==============================] - 0s 33us/step - loss: 0.3271 - acc: 0.8511\n",
      "Epoch 93/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.3256 - acc: 0.8511\n",
      "Epoch 94/100\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.3237 - acc: 0.8588\n",
      "Epoch 95/100\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.3248 - acc: 0.8550\n",
      "Epoch 96/100\n",
      "262/262 [==============================] - 0s 37us/step - loss: 0.3190 - acc: 0.8588\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 73us/step - loss: 0.3188 - acc: 0.8626\n",
      "Epoch 98/100\n",
      "262/262 [==============================] - 0s 56us/step - loss: 0.3150 - acc: 0.8664\n",
      "Epoch 99/100\n",
      "262/262 [==============================] - 0s 42us/step - loss: 0.3149 - acc: 0.8702\n",
      "Epoch 100/100\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.3119 - acc: 0.8664\n",
      "130/130 [==============================] - 0s 8us/step\n",
      "262/262 [==============================] - 0s 15us/step\n",
      "[CV]  batch_size=40, epochs=100, score=0.8307692316862253, total=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "392/392 [==============================] - 0s 35us/step - loss: 0.6724 - acc: 0.6480\n",
      "Epoch 2/10\n",
      "392/392 [==============================] - 0s 33us/step - loss: 0.5814 - acc: 0.6684\n",
      "Epoch 3/10\n",
      "392/392 [==============================] - 0s 63us/step - loss: 0.5102 - acc: 0.6684\n",
      "Epoch 4/10\n",
      "392/392 [==============================] - 0s 103us/step - loss: 0.4888 - acc: 0.6684\n",
      "Epoch 5/10\n",
      "392/392 [==============================] - 0s 56us/step - loss: 0.4735 - acc: 0.6684\n",
      "Epoch 6/10\n",
      "392/392 [==============================] - 0s 109us/step - loss: 0.4651 - acc: 0.7628\n",
      "Epoch 7/10\n",
      "392/392 [==============================] - 0s 79us/step - loss: 0.4599 - acc: 0.7985\n",
      "Epoch 8/10\n",
      "392/392 [==============================] - 0s 101us/step - loss: 0.4525 - acc: 0.7959\n",
      "Epoch 9/10\n",
      "392/392 [==============================] - 0s 107us/step - loss: 0.4458 - acc: 0.7985\n",
      "Epoch 10/10\n",
      "392/392 [==============================] - 0s 68us/step - loss: 0.4393 - acc: 0.7985\n",
      "Best: 0.7857142917963923, using {'batch_size': 20, 'epochs': 10}\n",
      "0.7729591812406268 (0.03996033894334982) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.7857142817609164 (0.046508596950667946) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.7551020386875892 (0.04798325747422201) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7857142917963923 (0.0372861071952023) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.7602040869544964 (0.043676457630137215) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.7755102061343436 (0.015087460434070294) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7270408113087926 (0.02670831713062866) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7755102054501066 (0.058735728787621615) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.7627551079708703 (0.05265361568814188) with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define a random seed\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "# Start defining the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 1)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "# make a dictionary of the grid sarch parameters\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(random_state=seed), verbose=10)\n",
    "grid_result = grid.fit(X_standardized, y)\n",
    "\n",
    "# summarize the results\n",
    "print('Best: {0}, using {1}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7882653062745016, using {'dropout_rate': 0.1, 'learn_rate': 0.1}\n",
      "0.7474489811123634 (0.04243556048075224) with: {'dropout_rate': 0.0, 'learn_rate': 0.001}\n",
      "0.7704081670666227 (0.04884245247274631) with: {'dropout_rate': 0.0, 'learn_rate': 0.01}\n",
      "0.7755102072747386 (0.047007743195658765) with: {'dropout_rate': 0.0, 'learn_rate': 0.1}\n",
      "0.7372449011522897 (0.05252544251178863) with: {'dropout_rate': 0.1, 'learn_rate': 0.001}\n",
      "0.7627551055380276 (0.030524003086167706) with: {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "0.7882653062745016 (0.04183756638247275) with: {'dropout_rate': 0.1, 'learn_rate': 0.1}\n",
      "0.737244899631763 (0.02794941769941659) with: {'dropout_rate': 0.2, 'learn_rate': 0.001}\n",
      "0.7244897933334721 (0.017530627349477787) with: {'dropout_rate': 0.2, 'learn_rate': 0.01}\n",
      "0.7270408202798999 (0.08595045604557942) with: {'dropout_rate': 0.2, 'learn_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Define a random seed\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "# Start defining the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential(learn_rate, dropout_rate)\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = learn_rate)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(learn_rate = learn_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(random_state=seed), verbose=1)\n",
    "grid_result = grid.fit(X_standardized, y)\n",
    "\n",
    "# summarize the results\n",
    "print('Best: {0}, using {1}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   44.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.783163267282807, using {'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7704081693474127 (0.021758750998324163) with: {'activation': 'softmax', 'init': 'uniform'}\n",
      "0.7755102103157919 (0.025457968181117865) with: {'activation': 'softmax', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with: {'activation': 'softmax', 'init': 'zero'}\n",
      "0.7397959188235049 (0.046356807436444214) with: {'activation': 'relu', 'init': 'uniform'}\n",
      "0.7627551097955022 (0.006299306358668942) with: {'activation': 'relu', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with: {'activation': 'relu', 'init': 'zero'}\n",
      "0.783163267282807 (0.038952255123339344) with: {'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7500000080587913 (0.024557637438404292) with: {'activation': 'tanh', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with: {'activation': 'tanh', 'init': 'zero'}\n",
      "0.7806122523485398 (0.040868500335866316) with: {'activation': 'linear', 'init': 'uniform'}\n",
      "0.7729591896035233 (0.043608058971360955) with: {'activation': 'linear', 'init': 'normal'}\n",
      "0.6683673458744068 (0.040922317011154695) with: {'activation': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Define a random seed\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "# Start defining the model\n",
    "def create_model(activation, init):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer = init , activation = activation))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer = init, activation = activation))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.1)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'relu', 'tanh', 'linear']\n",
    "init = ['uniform', 'normal', 'zero']\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(activation = activation, init = init)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(random_state=seed), verbose=1)\n",
    "grid_result = grid.fit(X_standardized, y)\n",
    "\n",
    "# summarize the results\n",
    "print('Best: {0}, using {1}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n",
      "[CV] ... neuron1=4, neuron2=2, score=0.7633587840859216, total=   1.4s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.7633587890908918, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=2, score=0.8153846218035772, total=   1.0s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7251908360546782, total=   1.4s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.7480916098783944, total=   1.0s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=4, score=0.8076923122772803, total=   1.1s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7404580184521566, total=   1.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.7404580202721457, total=   1.2s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=4, neuron2=8, score=0.8153846126336318, total=   1.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... neuron1=8, neuron2=2, score=0.7251908351446836, total=   1.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ... neuron1=8, neuron2=2, score=0.7709923796071351, total=   1.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] .... neuron1=8, neuron2=2, score=0.807692303107335, total=   1.0s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7022900763358778, total=   1.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.7709923786971405, total=   0.8s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ... neuron1=8, neuron2=4, score=0.8076923214472257, total=   1.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] .... neuron1=8, neuron2=8, score=0.725190845154624, total=   1.0s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.7251908419696429, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ... neuron1=8, neuron2=8, score=0.8307692408561707, total=   0.8s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.7328244247509323, total=   1.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=2, score=0.8015267289321841, total=   1.1s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ... neuron1=16, neuron2=2, score=0.807692303107335, total=   1.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.7328244256609269, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ... neuron1=16, neuron2=4, score=0.755725191294692, total=   1.0s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=4, score=0.8000000027509836, total=   1.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ... neuron1=16, neuron2=8, score=0.755725194479673, total=   1.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7404580211821403, total=   0.8s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] .. neuron1=16, neuron2=8, score=0.7692307738157419, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7806122523485398, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.7806122523485398 (0.024493751974558504) with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7602040842175484 (0.03473599114683287) with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7653061242736116 (0.035275423917752326) with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.7678571442256168 (0.03373255787130141) with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.760204090299655 (0.04367646053335504) with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.760204087562707 (0.04970628662656186) with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.7806122462664332 (0.03394908458177765) with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.7627551024969743 (0.027855469783425218) with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.7551020455299592 (0.011747145792393825) with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Define a random seed\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "# Start defining the model\n",
    "def create_model(neuron1, neuron2):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1, input_dim = 8, kernel_initializer = 'uniform' , activation = 'tanh'))\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.1)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 20, verbose = 0)\n",
    "\n",
    "# define the grid search parameters\n",
    "neuron1 = [4, 8, 16]\n",
    "neuron2 = [2, 4, 8]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n",
    "\n",
    "# build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(random_state=seed), refit = True, verbose=10)\n",
    "grid_result = grid.fit(X_standardized, y)\n",
    "\n",
    "# summarize the results\n",
    "print('Best: {0}, using {1}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a random seed\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "# Start defining the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer = 'uniform' , activation = 'tanh'))\n",
    "    model.add(Dense(2, input_dim = 4, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = 0.1)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 20, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# generate predictions with optimal hyperparameters\n",
    "y_pred = grid.predict(X_standardized)\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221  41]\n",
      " [ 27 103]]\n",
      "0.826530612244898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.84      0.87       262\n",
      "          1       0.72      0.79      0.75       130\n",
      "\n",
      "avg / total       0.83      0.83      0.83       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a classification report\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                   5.000\n",
      "Glucose                     166.000\n",
      "BloodPressure                72.000\n",
      "SkinThickness                19.000\n",
      "Insulin                     175.000\n",
      "BMI                          25.800\n",
      "DiabetesPedigreeFunction      0.587\n",
      "Age                          51.000\n",
      "Outcome                       1.000\n",
      "Name: 14, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# example datapoint\n",
    "example = df.iloc[5]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction using our optimized deep neural network\n",
    "prediction = grid.predict(X_standardized[5].reshape(1, -1))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
